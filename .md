ğŸ” Full Flow Summary:

1. User sends a message (e.g., "yes") from frontend to /chat_agent.

2. Flask captures it and builds initial conversation state.

3. The LangGraph starts at the agent node, where llm.invoke() decides:

 - whether to respond normally or

 - call a tool like send_invoice_email.

4. If tool is needed, the graph goes to tool node.

5. Tool is invoked, response is added to messages.

6. Graph loops back to agent to continue the conversation.

7. When done, the last LLM or tool message is returned to frontend